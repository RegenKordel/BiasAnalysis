{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabulous-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source: https://towardsdatascience.com/how-to-solve-analogies-with-word2vec-6ebaf2354009\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "viral-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_glove_wiki = os.path.abspath('data/Wikipedia300.txt')\n",
    "path_w2v_wiki = os.path.abspath('data/Wikipedia300_w2v.txt')\n",
    "\n",
    "\n",
    "glove_file = datapath(path_glove_wiki)\n",
    "tmp_file = get_tmpfile(path_w2v_wiki)\n",
    "\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "\n",
    "path = os.path.abspath('data/Wikipedia300_w2v.txt')\n",
    "\n",
    "model_wiki = KeyedVectors.load_word2vec_format(path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "innovative-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_glove_cc = os.path.abspath('data/CommonCrawl300.txt')\n",
    "path_w2v_cc = os.path.abspath('data/CommonCrawl300_w2v.txt')\n",
    "\n",
    "\n",
    "glove_file = datapath(path_glove_cc)\n",
    "tmp_file = get_tmpfile(path_w2v_cc)\n",
    "\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "\n",
    "path = os.path.abspath('data/CommonCrawl300_w2v.txt')\n",
    "\n",
    "model_cc = KeyedVectors.load_word2vec_format(path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ancient-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_glove_tw = os.path.abspath('data/Twitter100.txt')\n",
    "path_w2v_tw = os.path.abspath('data/Twitter100_w2v.txt')\n",
    "\n",
    "\n",
    "glove_file = datapath(path_glove_tw)\n",
    "tmp_file = get_tmpfile(path_w2v_tw)\n",
    "\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "\n",
    "path = os.path.abspath('data/Twitter100_w2v.txt')\n",
    "\n",
    "model_tw = KeyedVectors.load_word2vec_format(path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "lasting-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_analogy(worda, wordb, wordc):\n",
    "    print(\"Wikipedia:\")\n",
    "    wiki = pd.DataFrame (model_wiki.most_similar(negative=[worda],positive=[wordb, wordc]),columns=[[wordc, 'cosine_sim']])\n",
    "    print(wiki)\n",
    "    print(\"CommonCrawl:\")\n",
    "    cc = pd.DataFrame (model_cc.most_similar(negative=[worda],positive=[wordb, wordc]),columns=[[wordc, 'cosine_sim']])\n",
    "    print(cc)\n",
    "    print(\"Twitter:\")\n",
    "    tw = pd.DataFrame (model_tw.most_similar(negative=[worda],positive=[wordb, wordc]),columns=[[wordc, 'cosine_sim']])\n",
    "    print(tw)\n",
    "    \n",
    "def compare_models_similarity(word):\n",
    "    print(\"Wikipedia:\") \n",
    "    wiki = pd.DataFrame (model_wiki.most_similar(positive=word),columns=[[word, 'cosine_sim']])\n",
    "    print(wiki)\n",
    "    print(\"CommonCrawl:\") \n",
    "    cc = pd.DataFrame (model_cc.most_similar(positive=word),columns=[[word, 'cosine_sim']])\n",
    "    print(cc)\n",
    "    print(\"Twitter:\") \n",
    "    twitter = pd.DataFrame (model_tw.most_similar(positive=word),columns=[[word, 'cosine_sim']])\n",
    "    print(twitter)\n",
    "    \n",
    "def compare_models_similarity_pairs(worda, wordb):\n",
    "    print(\"Wikipedia:\") \n",
    "    wikia = pd.DataFrame (model_wiki.most_similar(positive=worda),columns=[[worda, 'cosine_sim_a']])\n",
    "    wikib = pd.DataFrame (model_wiki.most_similar(positive=wordb),columns=[[wordb, 'cosine_sim_b']])\n",
    "    wiki = pd.concat([wikia, wikib], axis=1, join='inner') \n",
    "    print(wiki)\n",
    "    print(\"CommonCrawl:\") \n",
    "    cca = pd.DataFrame (model_cc.most_similar(positive=worda),columns=[[worda, 'cosine_sim_a']])\n",
    "    ccb = pd.DataFrame (model_cc.most_similar(positive=wordb),columns=[[wordb, 'cosine_sim_b']])\n",
    "    cc = pd.concat([cca, ccb], axis=1, join='inner') \n",
    "    print(cc)\n",
    "    print(\"Twitter:\") \n",
    "    twa = pd.DataFrame (model_tw.most_similar(positive=worda),columns=[[worda, 'cosine_sim_a']])\n",
    "    twb = pd.DataFrame (model_tw.most_similar(positive=wordb),columns=[[wordb, 'cosine_sim_b']])\n",
    "    tw = pd.concat([twa, twb], axis=1, join='inner') \n",
    "    print(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "responsible-hundred",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stronger', 0.6895867586135864),\n",
       " ('despite', 0.6242086291313171),\n",
       " ('weak', 0.6232478618621826),\n",
       " ('strongest', 0.622769832611084),\n",
       " ('robust', 0.6030492782592773),\n",
       " ('strength', 0.5954651236534119),\n",
       " ('consistent', 0.570941150188446),\n",
       " ('solid', 0.5683797001838684),\n",
       " ('support', 0.5610021352767944),\n",
       " ('very', 0.5595080852508545)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wiki.most_similar(positive=\"strong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "christian-helmet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia:\n",
      "      women cosine_sim\n",
      "0       men   0.765692\n",
      "1     girls   0.634720\n",
      "2    female   0.618349\n",
      "3     woman   0.604761\n",
      "4      male   0.549830\n",
      "5   mothers   0.531372\n",
      "6  athletes   0.526854\n",
      "7       she   0.513752\n",
      "8     young   0.513321\n",
      "9  children   0.507967\n",
      "CommonCrawl:\n",
      "     women cosine_sim\n",
      "0      men   0.825095\n",
      "1   ladies   0.724850\n",
      "2    woman   0.717893\n",
      "3    girls   0.705516\n",
      "4    Women   0.690789\n",
      "5  females   0.678750\n",
      "6   female   0.655832\n",
      "7   womens   0.648444\n",
      "8  mothers   0.618875\n",
      "9    males   0.616936\n",
      "Twitter:\n",
      "     women cosine_sim\n",
      "0    woman   0.805092\n",
      "1    girls   0.770198\n",
      "2      men   0.747575\n",
      "3   ladies   0.747394\n",
      "4   womens   0.740094\n",
      "5   female   0.736097\n",
      "6  females   0.711881\n",
      "7    other   0.704463\n",
      "8     they   0.699757\n",
      "9   people   0.696706\n"
     ]
    }
   ],
   "source": [
    "compare_models_similarity(\"women\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dress-flash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia:\n",
      "       girl cosine_sim_a       boy cosine_sim_b\n",
      "0       boy     0.827289      girl     0.827289\n",
      "1     woman     0.729642      boys     0.681233\n",
      "2     girls     0.722729       kid     0.655293\n",
      "3  teenager     0.650977       man     0.620828\n",
      "4   teenage     0.649272   teenage     0.597385\n",
      "5    mother     0.641797     child     0.595288\n",
      "6      boys     0.628358  teenager     0.589650\n",
      "7     child     0.622930    father     0.580069\n",
      "8      teen     0.612524     girls     0.574547\n",
      "9  daughter     0.605021       son     0.572696\n",
      "CommonCrawl:\n",
      "      girl cosine_sim_a       boy cosine_sim_b\n",
      "0    girls     0.824546      girl     0.814832\n",
      "1      boy     0.814832       kid     0.780285\n",
      "2    woman     0.770079      boys     0.770499\n",
      "3     lady     0.755798       man     0.704570\n",
      "4     teen     0.740762  teenager     0.691475\n",
      "5     sexy     0.724625     young     0.684768\n",
      "6   blonde     0.695936       dad     0.679083\n",
      "7  teenage     0.691481     daddy     0.678516\n",
      "8    chick     0.688600       lad     0.675714\n",
      "9     babe     0.688469   brother     0.665973\n",
      "Twitter:\n",
      "        girl cosine_sim_a      boy cosine_sim_b\n",
      "0        boy     0.868402     girl     0.868402\n",
      "1      girls     0.855909      kid     0.835159\n",
      "2        she     0.853111     dude     0.823087\n",
      "3     friend     0.823827      guy     0.808023\n",
      "4        guy     0.822209     baby     0.803494\n",
      "5      chick     0.811896      lil     0.801286\n",
      "6       like     0.810003  brother     0.787051\n",
      "7     sister     0.809487    young     0.781294\n",
      "8  boyfriend     0.801070      old     0.778369\n",
      "9      bitch     0.799519    nigga     0.777073\n"
     ]
    }
   ],
   "source": [
    "compare_models_similarity_pairs(\"girl\", \"boy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "marked-contemporary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia:\n",
      "        woman cosine_sim\n",
      "0   physician   0.609857\n",
      "1       nurse   0.605909\n",
      "2     doctors   0.591393\n",
      "3    pregnant   0.533370\n",
      "4     dentist   0.524034\n",
      "5     medical   0.511250\n",
      "6  pharmacist   0.504334\n",
      "7     surgeon   0.500094\n",
      "8      nurses   0.498949\n",
      "9  physicians   0.498566\n",
      "CommonCrawl:\n",
      "          woman cosine_sim\n",
      "0         nurse   0.692357\n",
      "1       doctors   0.667855\n",
      "2     physician   0.662202\n",
      "3      pregnant   0.650009\n",
      "4  gynecologist   0.626058\n",
      "5    pharmacist   0.620841\n",
      "6       midwife   0.609780\n",
      "7  pediatrician   0.598572\n",
      "8     pregnancy   0.592360\n",
      "9       medical   0.592073\n",
      "Twitter:\n",
      "         woman cosine_sim\n",
      "0      doctors   0.649473\n",
      "1       mother   0.609547\n",
      "2      dentist   0.588896\n",
      "3        birth   0.575608\n",
      "4  grandmother   0.566490\n",
      "5      midwife   0.566192\n",
      "6        nurse   0.558148\n",
      "7        child   0.551933\n",
      "8     daughter   0.545252\n",
      "9       father   0.541687\n"
     ]
    }
   ],
   "source": [
    "compare_models_analogy(\"man\", \"doctor\", \"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "individual-czech",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia: programmers\n",
      "CommonCrawl: programmers\n",
      "Twitter: developer\n"
     ]
    }
   ],
   "source": [
    "compare_models_analogy(\"man\", \"programmer\", \"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "unauthorized-pittsburgh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia: researcher\n",
      "CommonCrawl: researcher\n",
      "Twitter: researcher\n"
     ]
    }
   ],
   "source": [
    "compare_models_analogy(\"man\", \"scientist\", \"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "clean-times",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia: technician\n",
      "CommonCrawl: technician\n",
      "Twitter: technician\n"
     ]
    }
   ],
   "source": [
    "compare_models_analogy(\"man\", \"engineer\", \"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "interstate-intelligence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia: transatlantic\n",
      "CommonCrawl: Trans\n",
      "Twitter: indonesian\n"
     ]
    }
   ],
   "source": [
    "compare_models_analogy(\"man\", \"trans\", \"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bulgarian-clause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia:\n",
      "        woman cosine_sim\n",
      "0    stronger   0.540588\n",
      "1   strongest   0.496957\n",
      "2       women   0.456852\n",
      "3      robust   0.455113\n",
      "4     despite   0.453090\n",
      "5        weak   0.452220\n",
      "6         her   0.449586\n",
      "7  consistent   0.442298\n",
      "8      female   0.440086\n",
      "9     support   0.432728\n",
      "CommonCrawl:\n",
      "        woman cosine_sim\n",
      "0    stronger   0.593500\n",
      "1   strongest   0.535380\n",
      "2       women   0.523203\n",
      "3    strongly   0.522918\n",
      "4   extremely   0.504470\n",
      "5    strength   0.504092\n",
      "6  attractive   0.502718\n",
      "7    positive   0.502413\n",
      "8      robust   0.495524\n",
      "9        very   0.490195\n",
      "Twitter:\n",
      "         woman cosine_sim\n",
      "0     powerful   0.632457\n",
      "1       loving   0.607668\n",
      "2  independent   0.599768\n",
      "3        heart   0.596056\n",
      "4        truly   0.592127\n",
      "5        often   0.591227\n",
      "6    beautiful   0.589892\n",
      "7   passionate   0.585448\n",
      "8         very   0.582792\n",
      "9     strength   0.581564\n"
     ]
    }
   ],
   "source": [
    "compare_models_analogy(\"man\", \"strong\", \"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "sufficient-score",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia:\n",
      "         man cosine_sim\n",
      "0   stronger   0.549757\n",
      "1    despite   0.532143\n",
      "2       weak   0.531488\n",
      "3       good   0.520228\n",
      "4   strength   0.517391\n",
      "5      solid   0.507273\n",
      "6     robust   0.497557\n",
      "7       well   0.489479\n",
      "8  strongest   0.488160\n",
      "9     enough   0.476605\n",
      "CommonCrawl:\n",
      "         man cosine_sim\n",
      "0   stronger   0.612946\n",
      "1       good   0.604684\n",
      "2   strength   0.593914\n",
      "3       weak   0.587595\n",
      "4      solid   0.566812\n",
      "5       well   0.558645\n",
      "6  strongest   0.553546\n",
      "7      tough   0.534405\n",
      "8        but   0.533306\n",
      "9      great   0.533095\n",
      "Twitter:\n",
      "    man cosine_sim\n",
      "0   bro   0.661264\n",
      "1    we   0.645014\n",
      "2    so   0.639920\n",
      "3  true   0.633815\n",
      "4  hard   0.629617\n",
      "5  keep   0.618759\n",
      "6  haha   0.615891\n",
      "7  well   0.612242\n",
      "8  good   0.608737\n",
      "9   too   0.608365\n"
     ]
    }
   ],
   "source": [
    "compare_models_analogy(\"woman\", \"strong\", \"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "annoying-elder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stronger', 0.5497574806213379),\n",
       " ('despite', 0.5321428179740906),\n",
       " ('weak', 0.5314878225326538),\n",
       " ('good', 0.52022784948349),\n",
       " ('strength', 0.5173912048339844),\n",
       " ('solid', 0.5072730779647827),\n",
       " ('robust', 0.49755674600601196),\n",
       " ('well', 0.4894790053367615),\n",
       " ('strongest', 0.48816049098968506),\n",
       " ('enough', 0.47660502791404724)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model_wiki.most_similar(negative=[\"woman\"], \n",
    "                                positive=[\"strong\", \"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-imperial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
